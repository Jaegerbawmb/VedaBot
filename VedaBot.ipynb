{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f916b406-8155-4738-b211-5e72260a7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8308bcc-7f41-4729-9dbb-a0f5bf49ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking NLTK Data ---\n",
      "NLTK data not found. Attempting to download...\n",
      "NLTK data download complete (if successful).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Checking NLTK Data ---\")\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print(\"NLTK data (punkt, wordnet, stopwords) found.\")\n",
    "except LookupError:\n",
    "    print(\"NLTK data not found. Attempting to download...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    print(\"NLTK data download complete (if successful).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f40d701b-74ce-4fd5-b27d-bb2fac9a4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Loading Text File ---\n",
      "File loaded successfully!\n",
      "Loaded text size: 3449853 characters.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 1. Loading Text File ---\")\n",
    "file_path = 'Four-Vedas-English-Translation.txt'\n",
    "text_content = \"\"\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "    print(\"File loaded successfully!\")\n",
    "    print(f\"Loaded text size: {len(text_content)} characters.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please check the path.\")\n",
    "    exit() # Exit if file not found\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during file loading: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d76a3e76-e53d-4f20-9feb-d81fdda30b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Text Preprocessing and Basic Statistics ---\n",
      "Successfully split text into 36 hymns.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. Text Preprocessing and Basic Statistics ---\")\n",
    "hymn_raw_texts = re.split(r'\\n\\nHYMN [IVXLCDM]+\\. [A-Za-z\\s]+\\n', text_content)\n",
    "hymn_raw_texts = [h.strip() for h in hymn_raw_texts if h.strip()]\n",
    "print(f\"Successfully split text into {len(hymn_raw_texts)} hymns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d173ab0-5688-4002-b5ef-f2879183b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(STOPWORDS).union(set(stopwords.words('english')))\n",
    "\n",
    "custom_stopwords = {'thou', 'thee', 'thy', 'ye', 'hath', 'art', 'veda', 'english', 'translation', 'ab', 'keith', 'hymn'}\n",
    "stop_words = stop_words.union(custom_stopwords)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_document_for_analysis(doc_text, for_tfidf=False):\n",
    "    doc_text = doc_text.lower()\n",
    "    doc_text = re.sub(r'[^a-z\\s]', '', doc_text) \n",
    "    words = word_tokenize(doc_text)\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    return \" \".join(lemmatized_words) if for_tfidf else lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3463cf83-7869-4f7c-9fc8-8ef5edf930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_hymns_lda = [preprocess_document_for_analysis(hymn, for_tfidf=False) for hymn in hymn_raw_texts]\n",
    "\n",
    "all_lemmatized_words = []\n",
    "for hymn_word_list in processed_hymns_lda:\n",
    "    all_lemmatized_words.extend(hymn_word_list)\n",
    "\n",
    "# Calculate Basic Statistics\n",
    "word_counts = Counter(all_lemmatized_words)\n",
    "unique_word_count = len(word_counts)\n",
    "total_words = len(all_lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ce63cd9-1544-4a10-86b1-058cb720e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words (after lemmatization): 281679\n",
      "Unique words: 16883\n",
      "\n",
      "Top 20 Most Common Words (Overall):\n",
      "  indra: 4449\n",
      "  god: 4174\n",
      "  agni: 3771\n",
      "  verily: 2552\n",
      "  soma: 2511\n",
      "  sacrifice: 2463\n",
      "  come: 1849\n",
      "  like: 1848\n",
      "  heaven: 1839\n",
      "  earth: 1594\n",
      "  strength: 1567\n",
      "  let: 1544\n",
      "  men: 1493\n",
      "  lord: 1383\n",
      "  wealth: 1371\n",
      "  mighty: 1177\n",
      "  water: 1165\n",
      "  power: 1143\n",
      "  shall: 1134\n",
      "  forth: 1127\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total words (after lemmatization): {total_words}\")\n",
    "print(f\"Unique words: {unique_word_count}\")\n",
    "\n",
    "print(\"\\nTop 20 Most Common Words (Overall):\")\n",
    "for word, count in word_counts.most_common(20):\n",
    "    print(f\"  {word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86975126-bb7d-4294-9f59-388e46e49c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e48e2325-b115-48b9-900d-415b4d12a1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Topic Modeling and Theme Extraction (LDA) ---\n",
      "Number of unique tokens in dictionary (after filtering): 2602\n",
      "Number of documents (hymns) in corpus: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 3. Topic Modeling and Theme Extraction (LDA) ---\")\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_hymns_lda)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_hymns_lda]\n",
    "\n",
    "print(f\"Number of unique tokens in dictionary (after filtering): {len(dictionary)}\")\n",
    "print(f\"Number of documents (hymns) in corpus: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b3fea2e-4726-4b56-9c32-782e562fade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LDA with 5 topics. This might take a moment...\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5\n",
    "print(f\"Running LDA with {num_topics} topics. This might take a moment...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54e34213-0743-4c5a-93ae-aa73274248a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model training complete!\n",
      "\n",
      "--- Discovered Topics ---\n",
      "Topic #0: 0.025*\"hail\" + 0.012*\"sacrificer\" + 0.008*\"year\" + 0.008*\"homage\" + 0.008*\"breath\" + 0.007*\"yonder\" + 0.007*\"season\" + 0.007*\"brahman\" + 0.006*\"verse\" + 0.006*\"pavamana\"\n",
      "Topic #1: 0.004*\"hail\" + 0.002*\"year\" + 0.002*\"sacrificer\" + 0.002*\"breath\" + 0.002*\"pavamana\" + 0.001*\"brahman\" + 0.001*\"yonder\" + 0.001*\"verse\" + 0.001*\"homage\" + 0.001*\"animal\"\n",
      "Topic #2: 0.004*\"hail\" + 0.002*\"sacrificer\" + 0.002*\"homage\" + 0.002*\"breath\" + 0.002*\"year\" + 0.002*\"said\" + 0.001*\"yonder\" + 0.001*\"brahman\" + 0.001*\"season\" + 0.001*\"pavamana\"\n",
      "Topic #3: 0.009*\"mitravaruna\" + 0.005*\"indravaruna\" + 0.005*\"sweetness\" + 0.005*\"nasatyas\" + 0.005*\"abundance\" + 0.005*\"travel\" + 0.004*\"visvedevas\" + 0.004*\"went\" + 0.003*\"shelter\" + 0.003*\"victory\"\n",
      "Topic #4: 0.007*\"pavamana\" + 0.006*\"indu\" + 0.003*\"jatavedas\" + 0.003*\"een\" + 0.003*\"effused\" + 0.002*\"purified\" + 0.002*\"nasatyas\" + 0.002*\"run\" + 0.002*\"rbhus\" + 0.002*\"envoy\"\n",
      "\n",
      "--- Top Topic for First 5 Hymns ---\n",
      "Hymn 1: Dominant Topic #4 (Probability: 0.97)\n",
      "Hymn 2: Dominant Topic #4 (Probability: 0.97)\n",
      "Hymn 3: Dominant Topic #4 (Probability: 0.96)\n",
      "Hymn 4: Dominant Topic #4 (Probability: 1.00)\n",
      "Hymn 5: Dominant Topic #4 (Probability: 1.00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=num_topics,\n",
    "                         random_state=42, \n",
    "                         passes=15,    \n",
    "                         per_word_topics=True,\n",
    "                         minimum_probability=0.01 \n",
    "                        )\n",
    "    print(\"LDA Model training complete!\")\n",
    "\n",
    "    print(\"\\n--- Discovered Topics ---\")\n",
    "    for idx, topic in lda_model.print_topics(num_words=10):\n",
    "        print(f\"Topic #{idx}: {topic}\")\n",
    "\n",
    "    print(\"\\n--- Top Topic for First 5 Hymns ---\")\n",
    "    for i, doc_bow in enumerate(corpus[:5]):\n",
    "        topic_probabilities = lda_model.get_document_topics(doc_bow, minimum_probability=0.0)\n",
    "        if topic_probabilities:\n",
    "            dominant_topic = sorted(topic_probabilities, key=lambda x: x[1], reverse=True)[0]\n",
    "            print(f\"Hymn {i+1}: Dominant Topic #{dominant_topic[0]} (Probability: {dominant_topic[1]:.2f})\")\n",
    "        else:\n",
    "            print(f\"Hymn {i+1}: No dominant topic found (too short or no strong topic).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during LDA model training: {e}\")\n",
    "    print(\"This often indicates a memory issue. Try reducing 'num_topics' or 'passes'.\")\n",
    "\n",
    "# Clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db064e7f-7caf-4c52-87b9-7832b13fbc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51912ed8-f763-41f6-8269-af56fcb5a1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Keyword Extraction (TF-IDF) and Collocation Analysis ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Keyword Extraction (TF-IDF) and Collocation Analysis ---\")\n",
    "\n",
    "processed_hymn_strings_tfidf = [preprocess_document_for_analysis(hymn, for_tfidf=True) for hymn in hymn_raw_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81a7bf1a-32e7-49a4-b122-6d58cef63133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Keyword Extraction (TF-IDF) ---\n",
      "\n",
      "Top 10 Keywords for Hymn 1:\n",
      "  agni: 0.406\n",
      "  vayu: 0.312\n",
      "  come: 0.236\n",
      "  day: 0.197\n",
      "  god: 0.186\n",
      "  soma: 0.162\n",
      "  cherishers: 0.142\n",
      "  sapientminded: 0.142\n",
      "  law: 0.132\n",
      "  obtaineth: 0.127\n",
      "\n",
      "Top 10 Keywords for Hymn 2:\n",
      "  accept: 0.258\n",
      "  visvedevas: 0.225\n",
      "  come: 0.195\n",
      "  sarsavad: 0.176\n",
      "  libationpouring: 0.176\n",
      "  pi: 0.176\n",
      "  libation: 0.168\n",
      "  thought: 0.168\n",
      "  illuminates: 0.158\n",
      "  arc: 0.158\n",
      "\n",
      "Top 10 Keywords for Hymn 3:\n",
      "  indra: 0.669\n",
      "  song: 0.191\n",
      "  agni: 0.171\n",
      "  come: 0.138\n",
      "  praise: 0.138\n",
      "  wealth: 0.123\n",
      "  lord: 0.112\n",
      "  god: 0.111\n",
      "  soma: 0.087\n",
      "  rich: 0.083\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Keyword Extraction (TF-IDF) ---\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_hymn_strings_tfidf)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_top_tfidf_words(document_index, top_n=10):\n",
    "    tfidf_scores = tfidf_matrix[document_index].toarray().flatten()\n",
    "    sorted_indices = tfidf_scores.argsort()[-top_n:][::-1]\n",
    "    top_words = [(feature_names[i], tfidf_scores[i]) for i in sorted_indices]\n",
    "    return top_words\n",
    "\n",
    "for i in range(min(3, len(processed_hymn_strings_tfidf))):\n",
    "    print(f\"\\nTop 10 Keywords for Hymn {i+1}:\")\n",
    "    for word, score in get_top_tfidf_words(i):\n",
    "        print(f\"  {word}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "435d0787-d676-4135-838d-e5f3056fd1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collocation Analysis (Frequency-Based) ---\n",
      "\n",
      "Top 20 Bigrams (Frequency):\n",
      "  ('heaven', 'earth'): 317 occurrences\n",
      "  ('soma', 'juice'): 305 occurrences\n",
      "  ('soma', 'pavamana'): 282 occurrences\n",
      "  ('say', 'verily'): 275 occurrences\n",
      "  ('earth', 'heaven'): 246 occurrences\n",
      "  ('world', 'heaven'): 235 occurrences\n",
      "  ('indra', 'agni'): 193 occurrences\n",
      "  ('mitra', 'varuna'): 192 occurrences\n",
      "  ('come', 'hither'): 188 occurrences\n",
      "  ('verily', 'make'): 186 occurrences\n",
      "  ('drink', 'soma'): 180 occurrences\n",
      "  ('verily', 'win'): 177 occurrences\n",
      "  ('far', 'away'): 158 occurrences\n",
      "  ('song', 'praise'): 154 occurrences\n",
      "  ('varuna', 'mitra'): 152 occurrences\n",
      "  ('hymn', 'sama'): 136 occurrences\n",
      "  ('sama', 'griffith'): 136 occurrences\n",
      "  ('atharva', 'bloomfield'): 135 occurrences\n",
      "  ('hymn', 'atharva'): 135 occurrences\n",
      "  ('bay', 'steed'): 132 occurrences\n",
      "\n",
      "Top 20 Trigrams (Frequency):\n",
      "  ('hymn', 'sama', 'griffith'): 136 occurrences\n",
      "  ('hymn', 'atharva', 'bloomfield'): 135 occurrences\n",
      "  ('drink', 'soma', 'juice'): 70 occurrences\n",
      "  ('evermore', 'god', 'blessing'): 59 occurrences\n",
      "  ('preserve', 'evermore', 'god'): 57 occurrences\n",
      "  ('say', 'verily', 'make'): 50 occurrences\n",
      "  ('offer', 'cake', 'potsherd'): 45 occurrences\n",
      "  ('new', 'moon', 'sacrifice'): 40 occurrences\n",
      "  ('indra', 'drink', 'soma'): 38 occurrences\n",
      "  ('holy', 'power', 'brahman'): 33 occurrences\n",
      "  ('hail', 'hail', 'hail'): 32 occurrences\n",
      "  ('verily', 'find', 'support'): 32 occurrences\n",
      "  ('varuna', 'mitra', 'aryaman'): 30 occurrences\n",
      "  ('went', 'world', 'heaven'): 29 occurrences\n",
      "  ('verily', 'serf', 'prosperity'): 26 occurrences\n",
      "  ('say', 'verily', 'invokes'): 25 occurrences\n",
      "  ('let', 'choose', 'boon'): 24 occurrences\n",
      "  ('soma', 'pavamana', 'soma'): 24 occurrences\n",
      "  ('verily', 'recourse', 'indra'): 24 occurrences\n",
      "  ('verily', 'win', 'cattle'): 24 occurrences\n",
      "\n",
      "--- All foundational NLP analyses complete! ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Collocation Analysis (Frequency-Based) ---\")\n",
    "\n",
    "bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(all_lemmatized_words)\n",
    "bigram_finder.apply_freq_filter(5) \n",
    "print(\"\\nTop 20 Bigrams (Frequency):\")\n",
    "\n",
    "for bigram in bigram_finder.nbest(nltk.collocations.BigramAssocMeasures().raw_freq, 20):\n",
    "    count = bigram_finder.ngram_fd[bigram]\n",
    "    print(f\"  {bigram}: {count} occurrences\")\n",
    "\n",
    "trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(all_lemmatized_words)\n",
    "trigram_finder.apply_freq_filter(3) \n",
    "\n",
    "print(\"\\nTop 20 Trigrams (Frequency):\")\n",
    "\n",
    "for trigram in trigram_finder.nbest(nltk.collocations.TrigramAssocMeasures().raw_freq, 20):\n",
    "\n",
    "    count = trigram_finder.ngram_fd[trigram]\n",
    "    print(f\"  {trigram}: {count} occurrences\")\n",
    "\n",
    "print(\"\\n--- All foundational NLP analyses complete! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a494ba7-1a86-477b-a605-6ba41ba6afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07ee4b75-50d0-4a67-927e-53e13d17475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyBHu2Rfxzv6NDEfaiqex3VbIEa_7pNFzLM') \n",
    "def get_collocation_explanation(collocation):\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash') \n",
    "    prompt = f\"In the context of ancient Indian texts like the Vedas, what is the significance and meaning of the phrase '{' '.join(collocation)}'? Explain its cultural, religious, or ritualistic context.\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93fd02e4-779d-4404-b2c6-8a37d695fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Explanation for 'soma juice' ---\n",
      "An error occurred: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "\n",
      "--- Explanation for 'drink soma juice' ---\n",
      "An error occurred: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "\n",
      "--- Explanation for 'heaven earth' ---\n",
      "An error occurred: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    }
   ],
   "source": [
    "example_bigram = ('soma', 'juice')\n",
    "explanation = get_collocation_explanation(example_bigram)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_bigram)}' ---\")\n",
    "print(explanation)\n",
    "\n",
    "example_trigram = ('drink', 'soma', 'juice')\n",
    "explanation_trigram = get_collocation_explanation(example_trigram)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_trigram)}' ---\")\n",
    "print(explanation_trigram)\n",
    "\n",
    "example_cosmic = ('heaven', 'earth')\n",
    "explanation_cosmic = get_collocation_explanation(example_cosmic)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_cosmic)}' ---\")\n",
    "print(explanation_cosmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5babf414-4b62-4187-b0cc-8b5d5e1aa85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Explanation for 'soma juice' ---\n",
      "In the Vedas, \"soma juice\" refers to a sacred drink prepared from a plant, the identity of which remains a matter of scholarly debate.  Its significance is multifaceted, deeply intertwined with religious ritual, cosmology, and the very fabric of Vedic society.\n",
      "\n",
      "**Significance and Meaning:**\n",
      "\n",
      "* **Divine Nectar:** Soma is frequently described as an ambrosia, a divine drink granting immortality, strength, and heightened spiritual awareness.  It's considered a gift from the gods, often associated with Indra, the king of the gods, who's depicted as gaining immense power and vigor from consuming it.\n",
      "\n",
      "* **Ritualistic Importance:** The preparation and consumption of soma formed the central act of many Vedic sacrifices (yajñas).  The elaborate process, involving crushing, straining, and mixing the plant with milk and water, was itself a sacred ritual, performed by specially trained priests.  The offering of soma to the gods was believed to establish communion between the human and divine realms.\n",
      "\n",
      "* **Source of Power and Inspiration:**  The consumption of soma is portrayed as leading to ecstatic experiences, heightened senses, and divine inspiration.  It enabled the priests to communicate with the gods and receive divine knowledge and blessings.  The hymns composed during the soma rituals (Soma hymns) are some of the most powerful and evocative sections of the Vedas.\n",
      "\n",
      "* **Cosmological Symbolism:** Soma's association with immortality and divine power connects it to the cosmic order.  Some interpretations link it to the moon, the sun, or even celestial waters.  Its cyclical preparation and consumption mirror cyclical processes in nature and the cosmos.\n",
      "\n",
      "\n",
      "**Cultural and Religious Context:**\n",
      "\n",
      "* **Vedic Religion:**  Soma was integral to the religious practices of the early Vedic people.  The hymns dedicated to it reveal much about their religious beliefs, cosmology, and social structure.  The ritual surrounding soma was a carefully regulated and highly valued activity, emphasizing the importance of ritual purity and the power of correctly performed sacrifice.\n",
      "\n",
      "* **Social Hierarchy:** The preparation and administration of soma was largely restricted to the Brahmin priests, highlighting their elevated status in the Vedic society.  Their specialized knowledge of the rituals and their role in mediating between humans and gods granted them significant power and influence.\n",
      "\n",
      "* **Poetry and Literature:** The Vedic hymns praising soma are masterpieces of early Indian literature, characterized by vivid imagery, rich symbolism, and powerful metaphors. They offer invaluable insights into the worldview and spiritual aspirations of the Vedic people.\n",
      "\n",
      "\n",
      "**The Mystery of Soma's Identity:**\n",
      "\n",
      "Despite its crucial role, the exact botanical identity of the soma plant remains unknown.  Numerous plants have been proposed, ranging from ephedra to fungi, but none fully satisfy all the descriptions in the Vedic texts. This uncertainty adds to the mystique surrounding soma and reinforces its symbolic significance.  It's possible that \"soma\" may represent not a single plant but a concept encompassing different plants used in various contexts or periods.\n",
      "\n",
      "\n",
      "In summary, soma juice in the Vedas is far more than just a drink; it's a powerful symbol of divine power, immortality, cosmic order, and the conduit through which humans could connect with the divine.  Its ritualistic use shaped Vedic religion, society, and literature, leaving a lasting impact on Indian culture.\n",
      "\n",
      "\n",
      "--- Explanation for 'drink soma juice' ---\n",
      "In the Vedic texts, \"drinking soma juice\" (Soma-pāna) holds profound significance as a central ritual act with far-reaching cultural, religious, and ritualistic implications.  Soma itself remains a subject of scholarly debate, with its precise botanical identification still uncertain, but its symbolic and ritualistic role is well-established.\n",
      "\n",
      "**Significance and Meaning:**\n",
      "\n",
      "* **Divine Nectar/Ambrosia:** Soma is frequently described as a divine nectar or ambrosia, a gift from the gods granting immortality, strength, and wisdom.  Drinking it wasn't merely about intoxication; it was about accessing divine power and experiencing a heightened state of consciousness.  The ritual aimed to establish a communion between humans and the divine.\n",
      "\n",
      "* **Sacrifice and Communion:** The Soma ritual was a crucial part of the Vedic sacrifices (yajña).  The pressing, offering, and drinking of Soma formed the core of many ceremonies, facilitating communication with the gods and securing their blessings.  The shared act of drinking bound participants together in a sacred communion.\n",
      "\n",
      "* **Spiritual Elevation:** The effects attributed to Soma include increased vitality, enhanced perception, ecstatic experiences, and even poetic inspiration.  The experience was seen as a pathway to spiritual elevation and enlightenment, enabling a closer connection with the divine realm.\n",
      "\n",
      "* **Social Bonding:** The elaborate Soma rituals brought together members of the community, reinforcing social bonds and reinforcing the social hierarchy. The process involved specialized priests, each with specific roles, emphasizing the social structure.\n",
      "\n",
      "* **Cosmic Order:** The Soma ritual was also associated with the maintenance of cosmic order (ṛta).  The precise procedures and recitations were believed to maintain balance and harmony in the universe.\n",
      "\n",
      "**Cultural, Religious, and Ritualistic Context:**\n",
      "\n",
      "* **Vedic Religion:** Soma was integral to the early Vedic religion, a key element of its sacrificial system.  The hymns of the Rig Veda dedicated to Soma are some of the most elaborate and poetic in the collection.\n",
      "\n",
      "* **Preparation and Offering:**  The preparation of Soma was a complex process, involving the extraction of its juice through crushing a plant. This juice was then mixed with milk and other ingredients, before being offered to the gods and consumed by the participants. The precise process and formulas varied across different Vedic schools.\n",
      "\n",
      "* **Recitation of Hymns:** The drinking of Soma was accompanied by the chanting of specific hymns (sāman), further enhancing the ritual's sacredness and its connection to the divine.\n",
      "\n",
      "* **Symbolism:** Beyond its literal meaning, Soma also carried symbolic significance, representing various things like the cosmic waters, the life-giving force of nature, or the divine essence itself.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "\"Drinking soma juice\" in the context of the Vedas wasn't simply an act of imbibing a beverage. It was a complex and multifaceted ritual act that served to connect humans with the divine, maintain cosmic order, reinforce social bonds, and access spiritual elevation.  Understanding its importance requires appreciating its intricate ritualistic procedures, its symbolic meanings, and its centrality within the Vedic sacrificial system.  While the precise nature of the plant remains elusive, its cultural and religious significance remains undeniable.\n",
      "\n",
      "\n",
      "--- Explanation for 'heaven earth' ---\n",
      "In the context of the Vedas and subsequent ancient Indian texts, the phrase \"heaven and earth\" (often expressed as *dyaus* and *prthvi* in Sanskrit) holds deep cosmological, religious, and ritualistic significance.  It doesn't simply refer to the physical sky and ground but represents a much broader, symbolic reality:\n",
      "\n",
      "* **Cosmological Order:**  *Dyaus* (heaven) and *prthvi* (earth) represent the fundamental duality that constitutes the cosmos.  They are the primary, opposing yet complementary forces that create and maintain the universe.  They are not just locations, but principles.  Heaven is often associated with the divine, the masculine, light, and the spiritual realm, while earth represents the material, the feminine, darkness, and the physical world. Their union is the foundation of existence.  The Rig Veda frequently mentions them as parents or progenitors of the cosmos, suggesting a creation myth rooted in their interaction.\n",
      "\n",
      "* **Ritualistic Importance:** Many Vedic rituals involved establishing a connection between heaven and earth.  Yajñas (sacrifices) were designed to create a sacred space that symbolically linked these two realms.  The altar, often built in a specific shape and orientation, represented the earth, while the smoke and offerings ascended to heaven.  This act established a communication channel between the human world and the divine, allowing for blessings and maintaining cosmic order.\n",
      "\n",
      "* **Divine Manifestation:**  The deities themselves were often understood through the lens of heaven and earth.  Indra, the king of gods, is associated with the heavens, while Prithvi (Earth) is sometimes personified as a goddess.  Their interactions, battles, and harmonious relationships reflect the dynamic interplay between these two fundamental forces.\n",
      "\n",
      "* **Cosmic Balance:** The integrity of the universe is dependent on the harmonious relationship between heaven and earth.  Disruptions or imbalances in this relationship were often seen as the cause of natural calamities, social unrest, or spiritual turmoil.  Rituals and practices aimed to restore this balance.\n",
      "\n",
      "* **Moral Order:**  The concept also extended to the human realm. The ideal human life was often viewed as a reflection of this cosmic harmony.  Ethical behavior, dharma, was seen as a way to maintain harmony within oneself, mirroring the balance between heaven and earth.\n",
      "\n",
      "In summary, \"heaven and earth\" in ancient Indian texts is not just a geographical description. It signifies a fundamental cosmic duality, the basis of creation, a framework for ritual practices, a representation of divine forces, and a model for understanding the ideal human life and maintaining cosmic and social order.  The phrase carries a profound weight, symbolizing the interconnectedness of the spiritual and material worlds, and the constant interplay between opposing but complementary forces.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_bigram = ('soma', 'juice')\n",
    "explanation = get_collocation_explanation(example_bigram)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_bigram)}' ---\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79a47372-c8da-4fac-a627-7f0e6d058eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Explanation for 'drink soma juice' ---\n",
      "In the Vedic texts, \"drink soma juice\" (Soma-pāna) is far more than a simple act of imbibing a beverage. It represents a complex ritual with profound cultural, religious, and social significance.  Soma itself is a mysterious and sacred plant, whose precise identity remains a topic of scholarly debate to this day.  Despite the uncertainty about its botanical origin, its symbolic importance is undeniable.\n",
      "\n",
      "**Significance and Meaning:**\n",
      "\n",
      "* **Divine Connection:**  Drinking Soma was believed to establish a direct connection with the divine. The ritual was considered a form of communion, allowing participants to experience a heightened state of awareness and interact with the gods.  The juice was considered a divine nectar, imbued with power and capable of granting immortality or at least extending life.\n",
      "\n",
      "* **Ritual Purity and Renewal:** The Soma ritual was a central part of Vedic sacrifices (yajñas). It was believed to purify both the participants and the offering, making it acceptable to the gods. The act of drinking the juice was a form of cleansing and spiritual renewal.\n",
      "\n",
      "* **Inspiration and Illumination:**  The Soma was not just a physical beverage; it was believed to inspire creativity, poetic insight, and profound spiritual understanding.  Many hymns of the Rigveda, arguably the most important collection of Vedic hymns, were composed and recited during Soma rituals, suggesting a link between the drink and poetic inspiration.  The experience was often described as ecstatic and revelatory.\n",
      "\n",
      "* **Social Cohesion:** The Soma rituals were communal events, bringing together priests (Brahmins), warriors (Kshatriyas), and other members of society.  The shared experience of drinking the sacred drink fostered a sense of unity and social cohesion within the community.  It reinforced social hierarchies as well, with the distribution and consumption of Soma strictly regulated according to social standing.\n",
      "\n",
      "* **Magical and Medicinal Properties:**  The Soma was also believed to possess medicinal properties, capable of curing diseases and bestowing strength and vitality.  This aspect links its consumption to both religious and secular practices.\n",
      "\n",
      "**Ritualistic Context:**\n",
      "\n",
      "The Soma ritual was an elaborate affair, involving complex procedures performed by trained priests. It included:\n",
      "\n",
      "* **Gathering and Preparation:** The Soma plant had to be carefully collected and processed.  Its preparation involved crushing, straining, and mixing with other ingredients like milk and water.\n",
      "* **Recitation of Hymns:**  Specific hymns from the Rigveda were recited throughout the ritual, invoking and praising the gods.\n",
      "* **Offering to the Gods:** The Soma juice was offered to the gods through libations.\n",
      "* **Consumption by Participants:**  Participants drank the Soma juice, experiencing its supposed intoxicating and spiritual effects.\n",
      "\n",
      "\n",
      "In summary, \"drink Soma juice\" in the Vedic context signifies much more than a simple act of drinking. It refers to a complex ritual act crucial for establishing a connection with the divine, achieving spiritual enlightenment, and reinforcing social bonds within the Vedic community. The mystery surrounding the plant's identity adds to its enduring allure and importance in the study of ancient Indian religion and culture.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_trigram = ('drink', 'soma', 'juice')\n",
    "explanation_trigram = get_collocation_explanation(example_trigram)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_trigram)}' ---\")\n",
    "print(explanation_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3558cbef-8e09-46bc-bc55-bb035eb320bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Explanation for 'heaven earth' ---\n",
      "In the Vedas and subsequent ancient Indian texts, the phrase \"heaven and earth\" (often rendered as *dyāvā-pṛthivī* in Sanskrit) signifies much more than a simple geographical description. It represents a fundamental cosmic duality, a foundational principle underpinning the entire cosmos and the structure of reality.  Its significance permeates various aspects of ancient Indian culture, religion, and ritual:\n",
      "\n",
      "**1. Cosmic Order and Creation:**  *Dyāvā-pṛthivī* represents the primordial cosmic couple, the parents of all creation.  Heaven (Dyau) is the masculine principle, representing the celestial realm, light, and the divine. Earth (Pṛthivī) is the feminine principle, representing the terrestrial realm, darkness, and the material world. Their union symbolizes the act of creation itself, the bringing forth of the universe from a state of primordial unity. Many Vedic hymns depict them as divine beings, actively involved in the processes of creation and sustenance.\n",
      "\n",
      "**2. Ritual and Sacrifice:**  The cosmic duality of heaven and earth is reflected in the structure and performance of Vedic sacrifices (yajñas).  The sacrificial altar often symbolically represents the earth, while the smoke rising from the fire ascends to the heavens. The offerings themselves are seen as mediating between these two realms, establishing a connection between the human world and the divine. The act of sacrifice is thus understood as a reenactment of the primordial creation, maintaining cosmic order.\n",
      "\n",
      "**3. Social Order:**  The complementary relationship between heaven and earth is often mirrored in the social order.  The king, representing the celestial realm, is responsible for maintaining dharma (righteousness) and order in the earthly realm, mirroring the cosmic balance between Dyau and Pṛthivī. The relationship between the king and his subjects echoes the symbiotic relationship between heaven and earth.\n",
      "\n",
      "**4. Moral and Ethical Framework:**  The concept of *dyāvā-pṛthivī* informs the ethical framework of ancient Indian thought.  Harmony between heaven and earth, reflecting the inner harmony between the divine and the material, is considered essential for a righteous life.  Actions that disrupt this harmony, either through disrespect towards nature or through unethical behavior, are viewed as disrupting the cosmic order and leading to imbalance.\n",
      "\n",
      "**5. Metaphorical Usage:**  Beyond its literal interpretation, \"heaven and earth\" is used metaphorically to represent vastness, totality, and the entirety of existence. It can signify the complete universe, encompassing all beings and phenomena.  It is also used to emphasize the magnitude of something, or to express awe and wonder.\n",
      "\n",
      "\n",
      "In conclusion, \"heaven and earth\" in the Vedic context is not merely a geographical expression. It is a profound cosmological concept, deeply embedded in the religious beliefs, rituals, social structures, and ethical framework of ancient Indian civilization. It reflects a holistic worldview that sees the universe as an interconnected and interdependent entity, where the divine and the material are inextricably linked.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_cosmic = ('heaven', 'earth')\n",
    "explanation_cosmic = get_collocation_explanation(example_cosmic)\n",
    "print(f\"\\n--- Explanation for '{' '.join(example_cosmic)}' ---\")\n",
    "print(explanation_cosmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ae0e429-43cd-4729-b95a-0fa0ff6fafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "995dc549-3d7f-4021-928a-d97de8209f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vedas text loaded successfully from file.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('Four-Vedas-English-Translation.txt', 'r', encoding='utf-8') as f:\n",
    "        full_vedas_text_content = f.read()\n",
    "    print(\"Vedas text loaded successfully from file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Four-Vedas-English-Translation.txt' not found.\")\n",
    "    print(\"Please ensure the file is in the same directory or provide the full path.\")\n",
    "    full_vedas_text_content = \"\"\n",
    "if not full_vedas_text_content:\n",
    "    print(\"Cannot proceed without Vedas text content. Please resolve the file loading issue.\")\n",
    "    exit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40e3610e-1ba4-4983-858e-72c4d3f0d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "local_embedding_model = SentenceTransformer(embedding_model_name, device=device)\n",
    "\n",
    "llm_model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4a66cf4-c3ff-4494-8958-9e470fb57f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485f8c6ff30f4ee59934378e6a234a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cc3124319e4c35ba65c8c4ad3952da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c858058ce4b54174bc0ea00221fd0a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac230171f7e4c3e967ac76d9aef866d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3728fcace9b4815a74154314a1104e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdb81f06cbe48b5a388b609951d86e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/621ffdc036468d709f17434d/63bed80836ee0758c8fd4f8975d59bb0b864263ee2753547c358e8a37cde8758?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T050855Z&X-Amz-Expires=3600&X-Amz-Signature=c61e6ea4eb26932f976e4e3137a491daf3208b45e0a35fa6f21a5c63cd4d6b5f&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=67aee77e7916701a3efd9d4f&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1751868535&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTg2ODUzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjFmZmRjMDM2NDY4ZDcwOWYxNzQzNGQvNjNiZWQ4MDgzNmVlMDc1OGM4ZmQ0Zjg5NzVkNTliYjBiODY0MjYzZWUyNzUzNTQ3YzM1OGU4YTM3Y2RlODc1OCoifV19&Signature=C4TF3VZXJ%7E1WBWWdWDiJS9a7EL-VCoEHdfXmGBhjxCaM22-dEHNg0koZVQgRrnvxI5vWUhqU2D3irGRvux3MLIi0X4-xY%7E7L4Loih8JTOaHrx7YVW4EJYH2waP1zFLb8yM37tAouNlRsP5sjto3NhudQ5x6P4NINAME%7El3m0O%7E35JL2nR0cdJ9%7EVgCTTj9DwMmIevHPSED6S8eifB8LMPEylSMQGLR2ri3scYPHgS80IYdxaFJKOrBTcYTYndLI0mLTAMxHVU3k72GOZ16oVVrDyuS3R7ER26uqrAHCIY2ifDfgfrzlXL067LPkX%7EHmp-s3joXLo1fF5327mmCGr7g__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1540c1c6e7bc46f8ace404291702d4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  84%|########4 | 461M/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62231b13ea8e4ab18fb21468a06dc242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "    if llm_tokenizer.pad_token is None:\n",
    "        llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "\n",
    "    llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name)\n",
    "    llm_model.to(device)\n",
    "\n",
    "    llm_model.eval()\n",
    "except Exception as e:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ded6f69d-204d-4bdd-8249-44a7c19d0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_local(text):\n",
    "    embedding = local_embedding_model.encode(text, convert_to_tensor=True, show_progress_bar=False)\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "def generate_response_local_llm(prompt):\n",
    "    inputs = llm_tokenizer.encode_plus(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = llm_model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=200,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=llm_tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    response_text = llm_tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70018abd-248b-4601-964c-b4c00aebabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hymn_pattern = r\"\\nHYMN\\s+([IVXLCDM]+\\.?\\s*\\.?\\s*|\\d+\\.?\\s*)([A-Za-z\\s\\(\\)-]+)\\.\\n\"\n",
    "hymn_sections = re.split(hymn_pattern, full_vedas_text_content)[1:]\n",
    "\n",
    "hymns_data = []\n",
    "for i in range(0, len(hymn_sections), 3):\n",
    "    hymn_identifier = hymn_sections[i].strip()\n",
    "    hymn_title_part = hymn_sections[i+1].strip()\n",
    "    full_hymn_title = f\"HYMN {hymn_identifier} {hymn_title_part}\"\n",
    "    hymns_data.append({\"title\": full_hymn_title, \"content\": hymn_sections[i+2].strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9865e426-dca5-4ad3-8d02-24f5f222a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "hymn_embeddings_list = []\n",
    "for hymn in hymns_data:\n",
    "    embedding = get_embedding_local(hymn['content'])\n",
    "    if embedding is not None:\n",
    "        hymn_embeddings_list.append(embedding)\n",
    "    else:\n",
    "        hymn_embeddings_list.append(None)\n",
    "\n",
    "for i, embedding in enumerate(hymn_embeddings_list):\n",
    "    hymns_data[i]['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0292fefd-4b10-49a4-be22-52e7fa6f4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vedas_df = pd.DataFrame(hymns_data)\n",
    "vedas_df = vedas_df.dropna(subset=['embedding'])\n",
    "\n",
    "if not vedas_df.empty:\n",
    "    document_embeddings = np.array(vedas_df['embedding'].tolist())\n",
    "else:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fe579-5a65-4d73-b6c9-62c0f72cf970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is the significance of agni\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agni can not be destroyed by a single blow, as he is the great-brother of the father who had a son.\n",
      "\n",
      "4. Agni was always on duty, and in the most perfect way.\n",
      "\n",
      "Agni is a hero and is always on guard against the danger of Agni.\n",
      "\n",
      "5. Agni is always well-wishers and always on his guard.\n",
      "\n",
      "Agni is a lover of the Lord, and in the same way loves Nrmedha.\n",
      "\n",
      "6. Agni is always on guard, and with him has been the most powerful and the most prosperous.\n",
      "\n",
      "Agni is always on guard against Agni, as it is the man who has given birth to him.\n",
      "\n",
      "7. Agni is always on guard, and in the same way loves Nrmedha.\n",
      "\n",
      "Agni is a husband, and a great lover of Nrmedha.\n",
      "\n",
      "8.\n",
      "- HYMN LXXX. Agni (Similarity: 0.67)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is the importance of indra\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know, verily, that this is a worthy praise.\n",
      "\n",
      "4. What is the purpose of the praise, and the purpose of the hymn, and the purpose of the hymn?\n",
      "\n",
      "Vedic Hymn Excerpts:\n",
      "\n",
      "--- HYMN XXVI. Indra ---\n",
      "\n",
      "1. What worthy praise will bring before us Indra, the Son of Strength, that he may grant us riches;\n",
      "\n",
      "For he the Hero, gives the singer treasures: he is the Lord who sends us gifts, ye people.\n",
      "\n",
      "2 To be invoked and hymned in fight with Vrtra, that well−praised Indra gives us real bounties.\n",
      "\n",
      "That Maghavan brings comfort in the venture to the religious man who pours libations.\n",
      "\n",
      "3 Him, verily, the men invoke in combat; risking their lives they make him their protector,\n",
      "\n",
      "When heroes, foe to foe, give up thei...\n",
      "\n",
      "- HYMN XXIV. Indra (Similarity: 0.59)\n"
     ]
    }
   ],
   "source": [
    "def find_similar_hymns_local(query, df, document_embeddings_array, top_k=1):\n",
    "    query_embedding = get_embedding_local(query)\n",
    "    if query_embedding is None:\n",
    "        return []\n",
    "\n",
    "    query_embedding_np = query_embedding.reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_embedding_np, document_embeddings_array).flatten()\n",
    "\n",
    "    actual_top_k = min(top_k, len(similarities))\n",
    "    top_indices = similarities.argsort()[-actual_top_k:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"title\": df.iloc[idx]['title'],\n",
    "            \"content\": df.iloc[idx]['content'],\n",
    "            \"similarity\": similarities[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_answer_from_context_local_llm(question, context_hymns_data):\n",
    "    limited_context_texts = []\n",
    "    for hymn in context_hymns_data:\n",
    "        limited_content = hymn['content'][:500] + \"...\" if len(hymn['content']) > 500 else hymn['content']\n",
    "        limited_context_texts.append(f\"--- {hymn['title']} ---\\n{limited_content}\")\n",
    "    \n",
    "    context_text = \"\\n\\n\".join(limited_context_texts)\n",
    "\n",
    "    prompt = f\"\"\"Based on the following Vedic hymn excerpts, answer the question below.\n",
    "If the information is not present, state that.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Vedic Hymn Excerpts:\n",
    "{context_text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return generate_response_local_llm(prompt)\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"\")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    relevant_hymns = find_similar_hymns_local(user_query, vedas_df, document_embeddings, top_k=1)\n",
    "\n",
    "    if not relevant_hymns:\n",
    "        continue\n",
    "\n",
    "    context_for_llm = [{\"title\": h['title'], \"content\": h['content']} for h in relevant_hymns]\n",
    "\n",
    "    final_answer = generate_answer_from_context_local_llm(user_query, context_for_llm)\n",
    "\n",
    "    print(final_answer)\n",
    "    for h in relevant_hymns:\n",
    "        print(f\"- {h['title']} (Similarity: {h['similarity']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a085e-316f-4839-9db1-4f3eda170d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
